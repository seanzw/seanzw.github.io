<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Zhengrong Wang</title>
    <link>https://seanzw.github.io/</link>
    <description>Recent content on Zhengrong Wang</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 06 Jul 2025 22:09:01 +0800</lastBuildDate>
    <atom:link href="https://seanzw.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>From Weeks to $0.01: Automating Analysis with RAG</title>
      <link>https://seanzw.github.io/posts/simple-document-rag/</link>
      <pubDate>Sun, 06 Jul 2025 22:09:01 +0800</pubDate>
      <guid>https://seanzw.github.io/posts/simple-document-rag/</guid>
      <description>&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;&#xA;&lt;!-- Recently, my friend came across a job to analyze&#xA;many public listed companies&#39; effort to handle ESG&#xA;(environment, sustainability, governance).&#xA;Specifically, based on its released report,&#xA;the company is evaluated on various dimension, e.g.&#xA;whether it tracks and releases its greenhouse gas emission&#xA;in a timely fashion, whether it sets the target to&#xA;tackle climate-related challenges in various time horizon, etc.&#xA;&#xA;In previous years, they simply recruited some interns,&#xA;each handling a subset of the companies and cross-check&#xA;each other&#39;s answer. The research associates (my friend&#xA;and the colleagues) performed a final check. Clearly, this&#xA;is time-consuming and error-pruning, as different people may&#xA;have different opinions (hence cross-checking). --&gt;&#xA;&lt;p&gt;When my friend described her team&amp;rsquo;s annual ritual of analyzing corporate ESG reports, I understood why she was desperate for change. For years, interns manually scanned hundreds of PDF pages to answer precise questions: Does the company track all emission scopes? Have they set quantifiable 2030 decarbonization targets? The process consumed weeks as they cross-checked interpretations while research associates verified results.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Transformer as A Computer Architect</title>
      <link>https://seanzw.github.io/posts/note-on-transformer-flops/</link>
      <pubDate>Sun, 02 Mar 2025 22:42:20 +0800</pubDate>
      <guid>https://seanzw.github.io/posts/note-on-transformer-flops/</guid>
      <description>&lt;h1 id=&#34;understanding-transformer-decoder&#34;&gt;Understanding Transformer Decoder&lt;/h1&gt;&#xA;&lt;p&gt;I have been extremly late to the party of transformer,&#xA;and here is my note on understanding the flops, data&#xA;movements, compute intensity, etc.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Note: For simplicity, I omit the data type for now.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;decoder-only-transformer&#34;&gt;Decoder-Only Transformer&lt;/h2&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s start with something simple: a decoder-only transformer.&#xA;Also, we skip the initial step to map token into the dictionary&#xA;space with positionary encoding. If we look at a single layer&#xA;of the decoder architecture, it contains three parameters:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Benchmarking GEMM on Modern CPU</title>
      <link>https://seanzw.github.io/posts/evaluate-gemm-on-epyc/</link>
      <pubDate>Wed, 30 Aug 2023 19:32:14 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/evaluate-gemm-on-epyc/</guid>
      <description>&lt;p&gt;Recently I got interested to understand what&amp;rsquo;s&#xA;the actual performance of GEMM on modern CPUs.&#xA;We all understand that GEMM is the backbone for&#xA;many critical applications and can never emphasize&#xA;enough how important to optimize it. That being&#xA;said, I never had a good first-hand experience&#xA;on benchmarking GEMM on modern CPUs, and here I am.&lt;/p&gt;&#xA;&lt;p&gt;We know that Intel has the famous MKL library that&#xA;is mainly optimized for Intel&amp;rsquo;s CPU (of course), and&#xA;there are open-sourced third party library such as&#xA;OpenBLAS (come with &lt;code&gt;numpy&lt;/code&gt; if you install using&#xA;&lt;code&gt;pip&lt;/code&gt;). However, what&amp;rsquo;s our choice for AMD architectures?&#xA;It turns out they also have their own optimized&#xA;library &amp;ndash; AOCL (AMD Optmized CPU Library). And&#xA;even better, AOCL is open-sourced (unlike MKL).&#xA;Let&amp;rsquo;s start our journey now.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bring AVX Support to Gem5</title>
      <link>https://seanzw.github.io/posts/gem5-avx/</link>
      <pubDate>Sun, 20 Dec 2020 20:16:06 -0800</pubDate>
      <guid>https://seanzw.github.io/posts/gem5-avx/</guid>
      <description>&lt;h2 id=&#34;tldr&#34;&gt;TL;DR&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/seanzw/gem5-avx&#34;&gt;gem5-avx&lt;/a&gt; brings partial&#xA;AVX2 and AVX-512 support to gem5. Feel free to use it for your&#xA;research at your own risk. There is a short guide on how to add&#xA;new instructions at the end of this post. Issues and pull requests&#xA;are welcome!&lt;/p&gt;&#xA;&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;&#xA;&lt;p&gt;During my research this year, I had to implement AVX2 and AVX-512 in&#xA;gem5, as I could not find a good online. Eventually I had a partial&#xA;implementation which works for the workloads I looked into. Luckily,&#xA;the paper gets published in this year&amp;rsquo;s HPCA, and I have already&#xA;released the code for that project: &lt;a href=&#34;https://github.com/PolyArch/gem-forge-framework/&#34;&gt;gem-forge&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GEM5 O3 CPU Backend</title>
      <link>https://seanzw.github.io/posts/gem5-o3-backend/</link>
      <pubDate>Fri, 03 Jul 2020 12:14:04 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/gem5-o3-backend/</guid>
      <description>&lt;p&gt;This is my note on reading GEM5&amp;rsquo;s O3 cpu backend. I could not find a&#xA;good document online, and the code is a little bit entangled and tricky&#xA;to understand. So here I would extract the key function chain to show&#xA;how an instruction is handled by the backend.&lt;/p&gt;&#xA;&lt;p&gt;Hopefully this could help more people. I assume you are already familiar&#xA;with GEM5.&lt;/p&gt;&#xA;&lt;h2 id=&#34;compute-instructions&#34;&gt;Compute Instructions&lt;/h2&gt;&#xA;&lt;p&gt;Compute instructions are simpler as they do not access memory and&#xA;not interact with the LSQ. It is actually pretty straightforward and&#xA;here is a high-level description.&#xA;I first show the calling chain (only important&#xA;functions), and then describe its functionality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Simulating SPEC2017 on GEM5</title>
      <link>https://seanzw.github.io/posts/gem5-spec2017/</link>
      <pubDate>Wed, 11 Mar 2020 14:19:34 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/gem5-spec2017/</guid>
      <description>&lt;h1 id=&#34;brief-note-on-simulating-spec2017-on-gem5&#34;&gt;Brief Note on Simulating SPEC2017 on GEM5&lt;/h1&gt;&#xA;&lt;p&gt;This is a brief note on how to simulate SPEC2017 on gem5. SPEC2017 has complicated compile scripts. The basic workflow is to compile it, do a fake run to get the&#xA;arguments for the binary, and finally simulate it in gem5. This is by no means the official instructions or guaranteed to work on your machine.&#xA;You can also follow the instructions on the official website of SPEC2017.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Swap Ctrl and Cap</title>
      <link>https://seanzw.github.io/posts/swap-ctrl-cap/</link>
      <pubDate>Fri, 13 Sep 2019 10:30:04 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/swap-ctrl-cap/</guid>
      <description>&lt;p&gt;I find it very convenient to swap the control and cap lock key. And here is how I achieve this in the OS I am using.&lt;/p&gt;&#xA;&lt;h3 id=&#34;ubuntu-1604&#34;&gt;Ubuntu 16.04&lt;/h3&gt;&#xA;&lt;p&gt;Somehow the &lt;code&gt;gnome-tweak-tool&lt;/code&gt; is not working in my case. I am using the following command line and it works like magic.&lt;/p&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;/usr/bin/setxkbmap -option &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;ctrl:swapcaps&amp;#34;&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
    </item>
    <item>
      <title>Extend RISC-V ISA with Matrix Multiply</title>
      <link>https://seanzw.github.io/posts/risc-v-isa-extension/</link>
      <pubDate>Fri, 28 Jun 2019 14:55:52 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/risc-v-isa-extension/</guid>
      <description>&lt;p&gt;Many computer architecture students will eventually add some new (useless)&#xA;instructions to a ISA, and there are many great tutorial on how to do this. This is&#xA;yet another notes on my struggling to extend RISC-V with a new matrix multiply&#xA;instruction. The overall goal is to add a new functional unit in a general purpose&#xA;processor to do a 4x4 matrix multiply accumulate with single-precision&#xA;floating-point.&lt;/p&gt;&#xA;&lt;p&gt;The &lt;a href=&#34;https://content.riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf&#34;&gt;Manual&lt;/a&gt; has a very detailed explanation on what ISA encoding is reserved for such non-standard extension (see ch.21). Basially any instruction with a prefix (starting from LSB) &lt;code&gt;00 010 11&lt;/code&gt; or &lt;code&gt;01 010 11&lt;/code&gt; is reserved.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setup This Website with Hugo</title>
      <link>https://seanzw.github.io/posts/setting-up-this/</link>
      <pubDate>Fri, 29 Mar 2019 15:41:55 -0700</pubDate>
      <guid>https://seanzw.github.io/posts/setting-up-this/</guid>
      <description>&lt;p&gt;After 2 years with my previous dummy personal website, I was urged to create a better one. After some googling, I made this tiny website using &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt;. Here are some notes for a n00b in front-end like me.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Make sure you download the &lt;strong&gt;extended&lt;/strong&gt; version of Hugo. Otherwise you won&amp;rsquo;t have support for SASS and SCSS (I have no idea what these are). Just scroll down in the &lt;a href=&#34;https://github.com/gohugoio/hugo/releases&#34;&gt;release page&lt;/a&gt; and you will find it.&lt;/li&gt;&#xA;&lt;li&gt;Create a new post with &lt;code&gt;hugo new posts/awesome-post.md&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;After you created some post, make sure to modify the &lt;strong&gt;draft&lt;/strong&gt; field to &lt;strong&gt;false&lt;/strong&gt;. Otherwise you will get a 404 in blog and spend half an hour wondering why.&lt;/li&gt;&#xA;&lt;li&gt;You can use icon from &lt;a href=&#34;https://fontawesome.com/&#34;&gt;Font Awesome&lt;/a&gt; by &lt;code&gt;&amp;lt;i class=&amp;quot;fab fa-github&amp;quot;&amp;gt;&amp;lt;/i&amp;gt;&lt;/code&gt;. And always remember that you can embed HTML directly in the markdown. This is a nice workaround if you can not get what you want from markdown.&lt;/li&gt;&#xA;&lt;li&gt;Use &lt;code&gt;hugo server&lt;/code&gt; to start the server. It will automatically detect any changes in the folder and rerender the website.&lt;/li&gt;&#xA;&lt;li&gt;This &lt;a href=&#34;https://gohugo.io/hosting-and-deployment/hosting-on-github/&#34;&gt;tutorial&lt;/a&gt; shows how to user Hugo with GitHub pages. Basically they are using git submodule.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;I hope this is useful someday.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://seanzw.github.io/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seanzw.github.io/about/</guid>
      <description>&lt;h1 id=&#34;about-me&#34;&gt;About Me&lt;/h1&gt;&#xA;&lt;p&gt;I am a computer architect researcher. I am generally interested in developing high performance computer architecture for both general and domain specific computing with compiler support. I am also looking into how to accurately and efficiently model and simulate current architectures.&lt;/p&gt;&#xA;&lt;p&gt;I was a postdoc at UCLA, working with &lt;a href=&#34;http://web.cs.ucla.edu/~tjn/&#34;&gt;Prof. Tony Nowatzki&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Prior joining UCLA, I received Bachelor of Engineering from Department of Electronic Enginerring, Tsinghua University. I also studied at ETH Zürich for half a year as a exhange student.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://seanzw.github.io/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seanzw.github.io/projects/</guid>
      <description>&lt;h1 id=&#34;projects---no-research-just-for-fun&#34;&gt;Projects - No Research Just for Fun&lt;/h1&gt;&#xA;&lt;h3 id=&#34;yart-yet-another-ray-tracer&#34;&gt;Yart-Yet Another Ray Tracer &lt;a href=https://github.com/seanzw/yart-cpp&gt;&lt;i class=&#34;fab fa-github&#34;&gt;&lt;/i&gt;&lt;/a&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Yart is a simple but powerful ray tracer engine. It reads in a scene description file and parses it. Then it renders the scene and prints the output image. For objects, it supports sphere and triangle mesh. For material, Lambertian, Specular, Refraction and Cook-Torrance BSDF are implemented. To solve the light equation, it can use either direct lighting or bidirectional path tracing. To accelerate the computation, multiple threads and OC-Tree are used.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>https://seanzw.github.io/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://seanzw.github.io/publications/</guid>
      <description>&lt;h1 id=&#34;publications&#34;&gt;Publications&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Zhengrong Wang&lt;/strong&gt;, Christopher Liu, Nathan Beckmann, Tony Nowatzki&lt;br&gt;&#xA;&lt;a href=&#34;&#34;&gt;Affinity Alloc: Taming &lt;del&gt;Not-So&lt;/del&gt; Near-Data Computing&lt;/a&gt;&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/micro2023-affinity-alloc.pdf&#34;&gt;pdf&lt;/a&gt;]&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/micro2023-affinity-alloc-slides.pdf&#34;&gt;slides&lt;/a&gt;]&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/micro2023-affinity-alloc-slides.pptx&#34;&gt;pptx&lt;/a&gt;]&lt;br&gt;&#xA;2023 ACM/IEEE 56th International Symposium on Microarchitecture (MICRO).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Zhengrong Wang&lt;/strong&gt;, Christopher Liu, Aman Arora, Lizy John, Tony Nowatzki&lt;br&gt;&#xA;&lt;a href=&#34;https://dl.acm.org/doi/10.1145/3582016.3582032&#34;&gt;Infinity Stream: Portable and Programmer-Friendly In-/Near-Memory Fusion&lt;/a&gt;&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/asplos2023-infinity-stream.pdf&#34;&gt;pdf&lt;/a&gt;]&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/asplos2023-infinity-stream-slides.pdf&#34;&gt;slides&lt;/a&gt;]&lt;br&gt;&#xA;2023 International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Zhengrong Wang&lt;/strong&gt;, Christopher Liu, Tony Nowatzki&lt;br&gt;&#xA;&lt;a href=&#34;https://ieeexplore.ieee.org/document/9872048&#34;&gt;Infinity Stream: Enabling Transparent and Automated In-Memory Computing&lt;/a&gt;&#xA;[&lt;a href=&#34;https://seanzw.github.io/pub/cal2022-infinity-stream.pdf&#34;&gt;pdf&lt;/a&gt;]&lt;br&gt;&#xA;Computer Architecture Letter 2022.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
